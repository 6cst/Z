# -*- coding: utf-8 -*-
"""NAIVExOD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hrDMnId8ozlk6mUikYXpefhQvSh3_tsl
"""

# 1. Import all Packages
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report
from collections import Counter

# 2. Import Dataset
df = pd.read_csv('/content/employee_data.csv')  # Replace with your file path

# 3. Display head, tail, describe, nulls, and duplicates
print("Head:\n", df.head())
print("Tail:\n", df.tail())
print("Describe:\n", df.describe(include='all'))
print("Null Values:\n", df.isnull().sum())
print("Duplicate Rows:", df.duplicated().sum())

# Drop nulls and duplicates
df.dropna(inplace=True)
df.drop_duplicates(inplace=True)

# 4. Label Encode Categorical Strings
le = LabelEncoder()
df['gender'] = le.fit_transform(df['gender'])  # Male=1, Female=0
bins = [0, 17000, 21000, 26000]
labels = ['Low', 'Medium', 'High']
df['purchase_category'] = pd.cut(df['car_purchased'], bins=bins, labels=labels)

# 5. Counter on Target Column
target_counter = Counter(df['car_purchased'])
print("Target Counter:\n", target_counter)

# 6. Data Visualization
# Pie Chart
plt.figure(figsize=(5, 5))
plt.pie(target_counter.values(), labels=target_counter.keys(), autopct='%1.1f%%')
plt.title("Car Purchased Distribution")
plt.show()

# Bar Plot
sns.barplot(x='gender', y='car_purchased', data=df)
plt.title("Car Purchased by Gender")
plt.show()

# Scatter Plot
plt.scatter(df['salary'], df['car_purchased'], color='purple')
plt.xlabel("Salary")
plt.ylabel("Car Purchased")
plt.title("Salary vs Car Purchased")
plt.show()

# 7. Outlier Detection (IQR Method and Boxplot)
Q1 = df['salary'].quantile(0.25)
Q3 = df['salary'].quantile(0.75)
IQR = Q3 - Q1
lower_bound = Q1 - 1.5 * IQR
upper_bound = Q3 + 1.5 * IQR

outliers = df[(df['salary'] < lower_bound) | (df['salary'] > upper_bound)]
print("\nOutliers Detected (Formula):\n", outliers)

# Boxplot
sns.boxplot(x='salary', data=df)
plt.title("Salary Outlier Boxplot")
plt.show()

# 8. Heatmap
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.title("Heatmap")
plt.show()

# 9. Data Processing (Split Features and Target)
df['car_purchased'] = df['car_purchased'].astype(str)  # Naive Bayes requires classification
X = df[['salary', 'gender', 'age']]
y = df['car_purchased']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 10. Naive Bayes Model
model = GaussianNB()
model.fit(X_train, y_train)

# 11. Accuracy & Metrics
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))



import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report

# Step 1: Load data
df = pd.read_csv("/content/employee_data.csv")

# Step 2: Clean data
df['car_purchased'] = pd.to_numeric(df['car_purchased'], errors='coerce')
df['salary'] = pd.to_numeric(df['salary'], errors='coerce')
df['age'] = pd.to_numeric(df['age'], errors='coerce')
df.dropna(subset=['salary', 'car_purchased', 'age', 'gender'], inplace=True)
df.drop_duplicates(inplace=True)

# Step 3: Encode gender
le = LabelEncoder()
df['gender'] = le.fit_transform(df['gender'])  # Male=1, Female=0

# Step 4: Outlier Detection using IQR for salary
#Q1 = df['salary'].quantile(0.25)
#Q3 = df['salary'].quantile(0.75)
#IQR = Q3 - Q1
#outlier_condition = (df['salary'] < (Q1 - 1.5 * IQR)) | (df['salary'] > (Q3 + 1.5 * IQR))
#outliers = df[outlier_condition]
#print("Outliers (Formula-Based):")
#print(outliers)
from scipy import stats
z_scores = np.abs(stats.zscore(df['salary']))
outliers_z = df[z_scores > 2]  # use 2 or 3 depending on tolerance
print("Outliers (Z-score method):\n", outliers_z)


# Step 5: Outlier Visualization
plt.figure(figsize=(8,4))
sns.boxplot(x=df['salary'])
plt.title("Salary Outliers (Boxplot)")
plt.show()

# Step 6: Binning car_purchased into categories
bins = [0, 17000, 21000, 26000]
labels = ['Low', 'Medium', 'High']
df['purchase_category'] = pd.cut(df['car_purchased'], bins=bins, labels=labels)

# Step 7: Prepare X, y for Naive Bayes
X = df[['salary', 'gender', 'age']]
y = df['purchase_category']

# Step 8: Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 9: Train Naive Bayes Model
model = GaussianNB()
model.fit(X_train, y_train)

# Step 10: Prediction and Evaluation
y_pred = model.predict(X_test)
print("Accuracy:", accuracy_score(y_test, y_pred))
print("Classification Report:\n", classification_report(y_test, y_pred))

# Step 11: Visualize Predictions
sns.countplot(x=y_pred)
plt.title("Predicted Purchase Categories")
plt.show()







































